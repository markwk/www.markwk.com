---
title: 'Language as Imitative, Intersubjective Communication, Pt. 2: Conversing beyond the Static, Cognitive Model of Language'
author: Mark Koester
layout: post
blr_date:
  - 2013-04-13
categories:
  - Animals
  - Language
  - phenomenology
---
# 

As we saw in [Part 1][1], many people, like my friend Mathieu, assume that language has an inherent, underlying grammar that allows us to speak and communicate together. Even though there may be different ways of speaking (like slang or different regional and social groups), these different ways of speaking (langages) are united, so the assumption goes, under the standard or official language. These differing forms of the French language exist, as my friend writes using the metaphor of the body politic, “as plural subdivisions of it [the standard language], like identitary (sic) limbs growing from a motherbody that should not be destroyed nor reduced, lest every limb might be agonizing by putting itself apart from any community.” Furthermore, this conception of language means that the rules and vocabulary are detachable such that they can be expressed in a separate dictionary or grammar book. Official language is, accordingly, the official reference by which we understand each other, the way in which language makes sense to us and doesn’t seem foreign.  
**Static, Cognitive Model of Language as a Reference Book**  
Much of Anglo-Saxon, analytic philosophy describes language in a similar way: in terms of being a reference book. The most famous example is the ***Turing Test***.  
The Turing Test was purposed in order to determine if an artificial intelligence computer could affectively imitate or mimic human communication such that an outside observer would be recognize or believe in the humanity of the computer’s responses. There are numerous examples of this idea in analytic philosophy. The basic idea was to have a machine that could mimic human communication so as to be indistinguishable from a normal human response. The test went that an observer would ask the same questions to a human respondent and an AI respondent, and both were suppose to respond. The key distinction was to reach a level of AI that one could not tell the difference between human responses and AI responses.  
The most interesting variation of the Turing Test I think is ***Searle’s Chinese room***:

 [1]: http://mysticatheist.blogspot.com/2008/02/language-as-imitative-intersubjective.html

> Now, Searle asks the audience to suppose that he is in a room in which he  
> receives Chinese characters, consults a book containing an English version of  
> the computer program, and processes the Chinese characters according to the  
> instructions in the book. Searle notes that he does not, of course, understand a  
> word of Chinese. He simply manipulates what to him are meaningless squiggles,  
> using the book and whatever other equipment is provided in the room, such as  
> paper, pencils, erasers, and filing cabinets. After manipulating the symbols,  
> Searle will produce the answer in Chinese. Since the computer passed the Turing  
> test, so does Searle running its program by hand: "Nobody just looking at my  
> answers can tell that I don't speak a word of Chinese," Searle writes.  
> Searle argues that his lack of understanding goes to show that computers do  
> not understand Chinese either, because they are in the same situation as he is.  
> They are mindless manipulators of symbols, just as he is. They don't understand  
> what they're "saying", just as he doesn't. Since they do not have conscious  
> mental states like "understanding", they can not properly be said to have minds.  
> (from “[Chinese Room” on  
> Wikipedia][2]) 
There is [an animated version of Searle’s Chinese Room at The Mind Project][3] as well as [some animations dealing with other modification along the same basis][4].  
The basic idea of the Chinese Room is that by way of a reference book you are able to mimic Chinese such that an outside observer doesn’t see the difference between your Chinese and that of a real Chinese speaker. According to the Turing Test and Searle’s Chinese Room, language is something static that mirrors states of affairs in the world, like in early Wittgenstein. But language isn’t like that. It is far from a static model but is more or less like a dynamic, active model of the “give and take” witnessed in real conversation. The person in the Chinese room is simply copying what the book tells him or her to say, and as such he or she doesn’t really understand Chinese.  
This would become obvious if we put the Chinese Room model to a real conversation test. As the conversation topic shifted from one thing to another, something just wouldn’t be right with the Chinese-room speaker, because this person or robot would be unable to see how meaning is changing and coming to be in the happening of conversation. In fact, new meaning, language and words are things that often come to be in conversation. These creative happenings of language could never be modeled by the Chinese Room, because the key assumption is that static phrases could be responded by a pre-programmed conversation or reference book. The model of language in the Chinese Room fails to understand how language is something intersubjective. The best conversations are collective happenings, are greater than their individual participants such that something new and ours is accomplished and created not by single, atomic individuals but by the dialogical togetherness of us.  
For Searle and others, the key distinction in the philosophy of mind is the ability able to not simply mimic but understand. Someone who memorizes this giant reference book of conversation is nothing less than a mindless zombie or a stupid parrot mimicking but never understanding. What matters is the ability to have a mind, which of course animals don’t have. Language, *as we all know*, is more than mere mimicry.  
As Peter Steeves brings up (1):

> here, then, is the root of the mistrust of the animal. Even if an animal offers  
> sounds that seem to be responses, they will never be anything other than  
> mimicry. The animal cannot know what he is saying, just as the man in the box  
> did not know, just as computer still do not know, and—supposedly—quite unlike  
> the way I am knowing right now just what these words I am using mean. (p. 3)

Ironically, everyone more or less agrees that “language is learned through mimicry—in the human, the ape, the parrot, the raven, the bee.” Infants are genetically and neurologically programmed “programmed” to attempt to mimic the world around them. They mimic everyone and everything—be it the family dog or their father and mother.  
***“Talking” Parrots: Conversations beyond Human Mimicry in  
Animals**  
*As anyone who has seen a talking parrot knows, animals are  
also quite gifted at the art of verbal mimicry as humans, [maybe even better as this video  
clip of Einstein shows][5]. These parrots can learn numerous things, but most  
philosophers of mind claim that there is something radically different about  
human and animal communication, namely that we have a mind and they do not.  
Maybe this example of talking parrots is a bad example, because teaching animals to do human activities is a poor way of showing their intelligence and the nature of their mind; in fact it is a poor way of being together and talking together with an animal.  
These performance animals are being trained to do things they are not normally meant to do. This isn’t a bad thing as such, but as animal trainers, we are trying to make something, to make a living do something specific. Our intention is not to communicate or to really understand the animal; our goal is to get them to be and do something purely unnatural.  
There is a kind of false or inauthentic communicating if our only goal is dressage, because we stop reading and listening to the animal and look for simply, animal repetition. Once that animal has succeeded in mimicking what we want of it, it is time to teach it something new. While the “talking” parrot might be speaking human words, we fail to listen to this animal in a reciprocal way such that we understand their language, their hybrid language of human and parrot needs speaks to us; we fail to have a conversation, because all we are looking for is a specified reaction.  
My cat and I had conversations. She spoke in a way that I recognized and understand and she spoke in a way that I recognized and understood. There were no codes or reference books. There were no reference languages that we had to communicate by. Nothing was preplanned from start. It was only the Other facing us in eyes, words, gestures, feelings and strange go-betweens. Everything was learned through a timely sharing of subtler languages than dictionaries or grammar books.  
Our conversations like all language were the textured happenings between us. Language has no absolute reference and never will. The only reference point is the face and the voice staring and speaking back. Humanly we are born into a conversation already in place, already in words. We live in an ocean of language. Everything has already been said, but in saying again we say something new, we add a new meaning by repeating.  
Language is always intersubjective. This is its beauty and this is why communication takes work and time and timely work to take place. Language doesn’t exist in grammar book. It exists in us—in sharing, in the between of borders and worlds, in the unexplainable shared happening of already and yet to be.

[To continue reading, go to part 3][6].

(1.) Steeves, H. Peter. “Monkey See,” *The Things Themselves: Phenomenology and the Return to the Everyday*. Albany : Sate University of New York Press, 2006.

 [2]: http://en.wikipedia.org/wiki/Chinese_room
 [3]: http://www.mind.ilstu.edu/curriculum/searle_chinese_room/searle_chinese_room.php
 [4]: http://www.mind.ilstu.edu/curriculum/searle_chinese_room/searle_robot_reply.php
 [5]: http://fr.youtube.com/watch?v=lSDFzg8_Wfg
 [6]: http://mysticatheist.blogspot.com/2008/02/language-as-imitative-intersubjective_6620.html